## PATTERN: LEVERAGE FUNCTION AS A SERVICE ##

### Rationale: 
Function as a service (FaaS) is a concept of serverless computing where the developer can deploy and run a “function” or piece of logic without worrying about the underlying server. The function is triggered and scaled by incoming events and killed after the events are processed. Billing is done based on consumption and executions and not on server instances. The most famous example of serverless ins AWS lambda while there are alternatives provided by each of the cloud vendors such as Azure functions, Google Cloud functions. In addition, there are now open source initiatives such as Open whisk which aims to bring a vendor agnostic solution while delivering the same benefits promised by the serverless stack.

According to latest surveys, serverless in general has come into the mainstream for enterprises that have prior experience in cloud and acts as a first exposure for enterprises experimenting with cloud technology in general. (Serverless, 2018) 

**Advantages of using Function as a service**
*	Suitable for light weight stateless services 
*	Native integration with many of cloud provider services. 
*	Lower operational and development costs. AWS lambdas for e.g. cost only 20 cents for 1 m requests per month 
*	A smaller cost to scale – Auto scaling, No upgrade overheads
*	Agile development and allow developers to focus on code and deliver fast
*	Reduces the complexity of overall architecture.

### Solution:
Use FaaS technologies such as AWS lambda, Azure function or Google function. A varied range of applications can be created by using fully serverless technologies as mentioned below:
*	A fully functional and dynamic site can be created using a rich UI using JS frameworks such as React or Vuejs supported by a fully serverless cloud enabled backend such as Api gateway, lambda, DynamoDB and S3 
*	A complex site served by a JS front end supported by Api gateway and business logic residing in managed container orchestrator such as Aws Fargate
*	Clickstream analytics: AWS Kinesis data firehose + Lambda
*	Ordered event processing: AWS kinesis + Lambda
*	Workflows: AWS Step functions + Lambda
*	Media transform on upload: AWS S3 Event + Lambda
*	On the fly Image resizing: AWS Lambda@Edge + Cloudfront

As per latest survey on serverless usage, the following use cases are most prevalent:
32% - Web and API serving
21% - Data Processing, e.g., batch ETL (database Extract, Transform, and Load)
17% - Integrating 3rd Party Services
16% - Internal tooling
8% - Chat bots e.g., Alexa Skills (SDK for Alexa AI Assistant)
6% - Internet of Things 
(EECS Department. University of California, 2019)

Currently there are some limitations of cloud functions which need to be evaluated against advantages, but for building stateless services, cloud functions must be the first alternative that needs to be evaluated before opting for alternatives. Following are some of current limitations of AWS lambdas:
*	Disk Space is 512 MB, Memory limits can be from 128 MB to 1536 MB
*	Execution time out for a function is maximized to 15 mins
*	Package constraints like size of deployment package (50 MB zipped)
*	Request and response payload size is maximum 6 MB (sync) and 256 KB (async)
*	ENI exhaustion when lambdas are deployed in a VPC
*	Cold start can be an issue if there are no active instances of your function to serve requests resulting in initialization time lag.  Time lag depends upon the programming language used and also increases if lambda is deployed in VPC as ENI attachment takes time. Use languages such Go, python, node.js instead of Java for better performance.
[Edit 13-Nov-19]: In Oct'19, AWS has made a significant update to improve cold start times especially for VPC-enabled lambda services.  With this update, cold start seems to become a non-issue. More details in this AWS post: rolled https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/

All the current popular FaaS offerings such as lambdas, Google functions and Azure functions are proprietary implementations. 
Knative (https://cloud.google.com/knative/) tries to address this by being an open source serverless platform that integrates well with the popular Kubernetes (henceforth named ‘k8s’) ecosystem. In addition to being an open standard, how KNative differs from pure FaaS offerings is that it combines the portability of container runtime with infrastructure abstraction and also provides capabilities to serve requests and events.  With Knative you can model computations on request in a supported framework of your choice (including Ruby on Rails, Django and Spring among others); subscribe, deliver and manage events; integrate with familiar CI and CD tools, build containers from source and most importantly designed to run as a service on any of the cloud providers and on-premise deployments. 

Additionally, one of the earlier challenges was that vendor managed services such as FaaS could not be replicated in local environment easily and required application deployment thru CLI or console for unit testing and verification. In AWS, there are alternatives such as the vendor provided SAM Local (https://github.com/awslabs/aws-sam-cli) and open source localstack (https://github.com/localstack/localstack) that promises to provide a test/mocking framework with support for more than 20 AWS managed services.

[Next - PATTERN: CONTAINERIZE APPLICATIONS](https://github.com/srikanthkotekar/ideasworthsharing/blob/master/Building-Modern-Cloud-Native-Apps/5.4%20PATTERN:%20CONTAINERIZE%20APPLICATIONS.md)

[Back to Pattern catalog](https://github.com/srikanthkotekar/ideasworthsharing/blob/master/Building-Modern-Cloud-Native-Apps/5.%20Cloud-Native%20Application%20Patterns.md)
